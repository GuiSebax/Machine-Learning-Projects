{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OHG7LNiGIrrx",
    "outputId": "03d4d5fa-75c4-455d-c2a8-9d3a9eb44f9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: pgmpy in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.1.26)\n",
      "Requirement already satisfied: networkx in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pgmpy) (3.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pgmpy) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pgmpy) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pgmpy) (1.5.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pgmpy) (2.1.1)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pgmpy) (3.1.2)\n",
      "Requirement already satisfied: torch in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pgmpy) (2.5.1)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pgmpy) (0.14.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pgmpy) (4.66.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pgmpy) (1.3.2)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pgmpy) (3.3.0)\n",
      "Requirement already satisfied: xgboost in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pgmpy) (2.1.2)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pgmpy) (0.8.3)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai->pgmpy) (0.6.10)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai->pgmpy) (2.22.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai->pgmpy) (2.151.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai->pgmpy) (2.35.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai->pgmpy) (5.28.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai->pgmpy) (2.9.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai->pgmpy) (4.9.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai->pgmpy) (1.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->pgmpy) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->pgmpy) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->pgmpy) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->pgmpy) (3.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from statsmodels->pgmpy) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from statsmodels->pgmpy) (24.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->pgmpy) (3.15.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->pgmpy) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->pgmpy) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->pgmpy) (68.2.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->pgmpy) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch->pgmpy) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->pgmpy) (0.4.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core->google-generativeai->pgmpy) (1.65.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core->google-generativeai->pgmpy) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (4.9)\n",
      "Requirement already satisfied: six in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from patsy>=0.5.6->statsmodels->pgmpy) (1.16.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai->pgmpy) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai->pgmpy) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai->pgmpy) (4.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch->pgmpy) (2.1.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic->google-generativeai->pgmpy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic->google-generativeai->pgmpy) (2.23.4)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai->pgmpy) (1.67.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai->pgmpy) (1.67.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai->pgmpy) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (2023.7.22)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Instalar a biblioteca pgmpy (se necessário)\n",
    "%pip install pgmpy\n",
    "\n",
    "# Importar bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.inference import VariableElimination\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6Mg8TGtuIvaz",
    "outputId": "57e52d2a-0e38-43b4-9d96-b665a97bd9ee"
   },
   "outputs": [],
   "source": [
    "# Carregar os dados do Titanic\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "# Discretizar Age em faixas etárias\n",
    "train_df['Age'] = pd.cut(train_df['Age'], bins=[0, 12, 18, 59, 120], labels=['criança', 'adolescente', 'adulto', 'idoso'])\n",
    "\n",
    "# Discretizar Fare em categorias: baixo, médio, alto\n",
    "train_df['Fare'] = pd.qcut(train_df['Fare'], q=3, labels=['baixo', 'médio', 'alto'])\n",
    "\n",
    "# Derivar 'Family_Size' como a soma de 'SibSp' e 'Parch'\n",
    "train_df['Family_Size'] = train_df['SibSp'] + train_df['Parch']\n",
    "\n",
    "# Derivar 'Cabin_type' como uma variável categórica\n",
    "# Aqui assumimos que, se a cabine começa com 'A', 'B', ou 'C', é alta, caso contrário é baixa.\n",
    "train_df['Cabin_type'] = train_df['Cabin'].apply(lambda x: 'alta' if pd.notna(x) and x[0] in ['A', 'B', 'C'] else 'baixa')\n",
    "\n",
    "# Adicionar a nova categoria 'n/a' às colunas categóricas antes de preencher os valores NaN\n",
    "train_df['Age'] = train_df['Age'].cat.add_categories('n/a')\n",
    "train_df['Embarked'] = train_df['Embarked'].astype('category').cat.add_categories('n/a')\n",
    "\n",
    "# Visualizar as primeiras linhas para verificar a discretização e as variáveis derivadas\n",
    "train_df[['Age', 'Fare', 'Family_Size', 'Cabin_type']].head()\n",
    "\n",
    "train_df.fillna({\n",
    "    'Age': 'n/a',\n",
    "    'Embarked': 'n/a'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-6\n",
    "\n",
    "def calculate_conditional_probabilities(data, target, conditions):\n",
    "    \"\"\"\n",
    "    Calcula as probabilidades condicionais de uma variável target dado um conjunto de condições,\n",
    "    com base nos dados fornecidos.\n",
    "    \"\"\"\n",
    "    if not conditions:\n",
    "        # Caso não haja condições, só computa a proporção e normaliza\n",
    "        counts = data[target].value_counts().sort_index()\n",
    "        counts = counts.replace(0, epsilon)\n",
    "        probabilities = counts / counts.sum()\n",
    "        return pd.DataFrame([probabilities.values], columns=probabilities.index)\n",
    "\n",
    "    # Obtém o conjunto dos valores possíveis para cada condição e para o target\n",
    "    condition_values = [data[condition].unique() for condition in conditions]\n",
    "    target_values = data[target].unique()\n",
    "\n",
    "    # Gera todas as combinações possíveis de valores das condições\n",
    "    all_combinations = list(itertools.product(*condition_values))\n",
    "    index = pd.MultiIndex.from_tuples(all_combinations, names=conditions)\n",
    "\n",
    "    # Agrupa os dados por condições e target\n",
    "    grouped_data = data.groupby(conditions + [target]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Reindexa para incluir todas as combinações possíveis\n",
    "    grouped_data = grouped_data.reindex(index=index, fill_value=0)\n",
    "\n",
    "    # Reindexa de novo para incluir todas as categorias possíveis do target\n",
    "    grouped_data = grouped_data.reindex(columns=target_values, fill_value=0)\n",
    "\n",
    "    # Adiciona epsilon para evitar probabilidades nulas\n",
    "    grouped_data = grouped_data.replace(0, epsilon)\n",
    "\n",
    "    # Normaliza as probabilidades\n",
    "    row_sums = grouped_data.sum(axis=1)\n",
    "    conditional_probs = grouped_data.div(row_sums, axis=0)\n",
    "\n",
    "    return conditional_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "nYe0um93Iwfd"
   },
   "outputs": [],
   "source": [
    "# Construir o modelo Bayesian Network com as variáveis derivadas\n",
    "model = BayesianNetwork([\n",
    "    ('Fare', 'Pclass'),\n",
    "    ('Embarked', 'Pclass'),\n",
    "    ('Pclass', 'Survived'),\n",
    "    ('Sex', 'Survived'),\n",
    "    ('Age', 'Survived'),\n",
    "    ('Pclass', 'SibSp'),\n",
    "    ('Pclass', 'Parch'),\n",
    "    ('SibSp', 'Family_Size'),\n",
    "    ('Parch', 'Family_Size'),\n",
    "    ('Cabin_type', 'Survived'),\n",
    "    ('Family_Size', 'Survived')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "0HVyV1BFIxyl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass                     3             1             2\n",
      "Fare  Embarked                                          \n",
      "baixo S         9.449541e-01  2.752294e-02  2.752294e-02\n",
      "      C         9.999999e-01  2.777778e-08  2.777778e-08\n",
      "      Q         1.000000e+00  1.851852e-08  1.851852e-08\n",
      "      n/a       3.333333e-01  3.333333e-01  3.333333e-01\n",
      "alto  S         2.435233e-01  5.958549e-01  1.606218e-01\n",
      "      C         1.075269e-08  9.139785e-01  8.602150e-02\n",
      "      Q         7.142856e-01  2.857142e-01  1.428571e-07\n",
      "      n/a       4.999995e-07  9.999990e-01  4.999995e-07\n",
      "médio S         4.291845e-01  2.575107e-02  5.450644e-01\n",
      "      C         7.692307e-01  2.564102e-08  2.307692e-01\n",
      "      Q         8.124999e-01  6.250000e-08  1.875000e-01\n",
      "      n/a       3.333333e-01  3.333333e-01  3.333333e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_17276\\146304179.py:25: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_data = data.groupby(conditions + [target]).size().unstack(fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "# CPD para Pclass, condicionado a Fare e Embarked\n",
    "cpd_pclass_data = calculate_conditional_probabilities(train_df, 'Pclass', ['Fare', 'Embarked'])\n",
    "print(cpd_pclass_data)\n",
    "cpd_pclass = TabularCPD(\n",
    "    variable='Pclass',\n",
    "    variable_card=3,\n",
    "    values=cpd_pclass_data.values.T.tolist(),\n",
    "    evidence=['Fare', 'Embarked'],\n",
    "    evidence_card=[3, 4]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c47fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CPD para Family_size, condicionado a Survived\n",
    "cpd_family_size_data = calculate_conditional_probabilities(train_df, 'Family_Size', ['Survived'])\n",
    "cpd_family_size = TabularCPD(\n",
    "    variable='Family_Size',\n",
    "    variable_card=9,\n",
    "    values=cpd_family_size_data.values.T.tolist(),\n",
    "    evidence=['Survived'],\n",
    "    evidence_card=[2]\n",
    ")\n",
    "model.add_cpds(cpd_family_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "XHyZAUyTI0Mo"
   },
   "outputs": [],
   "source": [
    "cpd_sex_data = calculate_conditional_probabilities(train_df, 'Sex', [])\n",
    "cpd_sex = TabularCPD(variable='Sex', variable_card=2, values=cpd_sex_data.values.T.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ntVqklvDI2F8"
   },
   "outputs": [],
   "source": [
    "cpd_age_data = calculate_conditional_probabilities(train_df, 'Age', [])\n",
    "cpd_age = TabularCPD(variable='Age', variable_card=5, values=cpd_age_data.values.T.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "o7UTbHISI4Va"
   },
   "outputs": [],
   "source": [
    "cpd_fare_data = calculate_conditional_probabilities(train_df, 'Fare', [])\n",
    "cpd_fare = TabularCPD(variable='Fare', variable_card=3, values=cpd_fare_data.values.T.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "uUcFckyZI5V4"
   },
   "outputs": [],
   "source": [
    "cpd_embarked_data = calculate_conditional_probabilities(train_df, 'Embarked', [])\n",
    "cpd_embarked = TabularCPD(variable='Embarked', variable_card=4, values=cpd_embarked_data.values.T.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "3Rg9rcS4I7y_"
   },
   "outputs": [],
   "source": [
    "# CPD para SibSp baseado em Pclass\n",
    "cpd_sibsp_data = calculate_conditional_probabilities(train_df, 'SibSp', ['Pclass'])\n",
    "cpd_sibsp = TabularCPD(\n",
    "    variable='SibSp',\n",
    "    variable_card=7,\n",
    "    values=cpd_sibsp_data.values.T.tolist(),\n",
    "    evidence=['Pclass'],\n",
    "    evidence_card=[3]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "vlcDBhOwI9BW"
   },
   "outputs": [],
   "source": [
    "# CPD para Parch baseado em Pclass\n",
    "cpd_parch_data = calculate_conditional_probabilities(train_df, 'Parch', ['Pclass'])\n",
    "cpd_parch = TabularCPD(\n",
    "    variable='Parch',\n",
    "    variable_card=7,\n",
    "    values=cpd_parch_data.values.T.tolist(),\n",
    "    evidence=['Pclass'],\n",
    "    evidence_card=[3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "e8Mocy19K5dy"
   },
   "outputs": [],
   "source": [
    "# CPD para Family_Size, baseado em SibSp e Parch\n",
    "cpd_family_size_data = calculate_conditional_probabilities(train_df, 'Family_Size', ['SibSp', 'Parch'])\n",
    "cpd_family_size = TabularCPD(\n",
    "    variable='Family_Size',\n",
    "    variable_card=9,\n",
    "    values=cpd_family_size_data.values.T.tolist(),\n",
    "    evidence=['SibSp', 'Parch'],\n",
    "    evidence_card=[7, 7]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "_69FE0o7K6fJ"
   },
   "outputs": [],
   "source": [
    "cpd_cabin_type_data = calculate_conditional_probabilities(train_df, 'Cabin_type', [])\n",
    "cpd_cabin_type = TabularCPD(variable='Cabin_type', variable_card=2, values=cpd_cabin_type_data.values.T.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "YMeQjJrLI_ON"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_17276\\146304179.py:25: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_data = data.groupby(conditions + [target]).size().unstack(fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "# CPD para Survived, atualizado com Cabin_type como evidência adicional\n",
    "cpd_survived_data = calculate_conditional_probabilities(train_df, 'Survived', ['Pclass', 'Sex', 'Age', 'Cabin_type', 'Family_Size'])\n",
    "cpd_survived = TabularCPD(\n",
    "    variable='Survived',\n",
    "    variable_card=2,\n",
    "    values=cpd_survived_data.values.T.tolist(),\n",
    "    evidence=['Pclass', 'Sex', 'Age', 'Cabin_type', 'Family_Size'],\n",
    "    evidence_card=[3, 2, 5, 2, 9]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZZwIzLA_JA0-",
    "outputId": "1a1e7abf-8910-4809-be60-ff9c62095949"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pgmpy:Replacing existing CPD for Family_Size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo válido: True\n"
     ]
    }
   ],
   "source": [
    "# Adicionar todos os CPDs ao modelo, incluindo os novos\n",
    "model.add_cpds(cpd_pclass, cpd_sex, cpd_age, cpd_fare, cpd_embarked, cpd_sibsp, cpd_parch, cpd_family_size, cpd_cabin_type, cpd_survived)\n",
    "\n",
    "# Validar o modelo\n",
    "model_valid = model.check_model()\n",
    "print(\"Modelo válido:\", model_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P9WOKDtyJCwG",
    "outputId": "fd68205b-37b7-4719-9e56-131aaf3b24d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade de sobrevivência dado que o passageiro está nas classes:\n",
      "Classe 3:\n",
      "+-------------+-----------------+\n",
      "| Survived    |   phi(Survived) |\n",
      "+=============+=================+\n",
      "| Survived(0) |          0.5082 |\n",
      "+-------------+-----------------+\n",
      "| Survived(1) |          0.4918 |\n",
      "+-------------+-----------------+\n",
      "Classe 1:\n",
      "+-------------+-----------------+\n",
      "| Survived    |   phi(Survived) |\n",
      "+=============+=================+\n",
      "| Survived(0) |          0.4861 |\n",
      "+-------------+-----------------+\n",
      "| Survived(1) |          0.5139 |\n",
      "+-------------+-----------------+\n",
      "Classe 2:\n",
      "+-------------+-----------------+\n",
      "| Survived    |   phi(Survived) |\n",
      "+=============+=================+\n",
      "| Survived(0) |          0.4853 |\n",
      "+-------------+-----------------+\n",
      "| Survived(1) |          0.5147 |\n",
      "+-------------+-----------------+\n",
      "Probabilidade de sobrevivência dado sexo\n",
      "Sexo male:\n",
      "+-------------+-----------------+\n",
      "| Survived    |   phi(Survived) |\n",
      "+=============+=================+\n",
      "| Survived(0) |          0.5057 |\n",
      "+-------------+-----------------+\n",
      "| Survived(1) |          0.4943 |\n",
      "+-------------+-----------------+\n",
      "Sexo female:\n",
      "+-------------+-----------------+\n",
      "| Survived    |   phi(Survived) |\n",
      "+=============+=================+\n",
      "| Survived(0) |          0.5015 |\n",
      "+-------------+-----------------+\n",
      "| Survived(1) |          0.4985 |\n",
      "+-------------+-----------------+\n",
      "Probabilidade do passageiro ter uma família grande dado que ele sobreviveu\n",
      "+----------------+--------------------+\n",
      "| Family_Size    |   phi(Family_Size) |\n",
      "+================+====================+\n",
      "| Family_Size(0) |             0.1026 |\n",
      "+----------------+--------------------+\n",
      "| Family_Size(1) |             0.0806 |\n",
      "+----------------+--------------------+\n",
      "| Family_Size(2) |             0.1294 |\n",
      "+----------------+--------------------+\n",
      "| Family_Size(3) |             0.1271 |\n",
      "+----------------+--------------------+\n",
      "| Family_Size(4) |             0.0948 |\n",
      "+----------------+--------------------+\n",
      "| Family_Size(5) |             0.1472 |\n",
      "+----------------+--------------------+\n",
      "| Family_Size(6) |             0.1463 |\n",
      "+----------------+--------------------+\n",
      "| Family_Size(7) |             0.0951 |\n",
      "+----------------+--------------------+\n",
      "| Family_Size(8) |             0.0769 |\n",
      "+----------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# Configurar o inferenciador da rede\n",
    "inference = VariableElimination(model)\n",
    "\n",
    "print(\"Probabilidade de sobrevivência dado que o passageiro está nas classes:\")\n",
    "classes = train_df['Pclass'].unique()\n",
    "for i,c in enumerate(classes):\n",
    "    prob_survived_given_class = inference.query(variables=['Survived'], evidence={'Pclass': i})\n",
    "    print(f\"Classe {c}:\")\n",
    "    print(prob_survived_given_class)\n",
    "\n",
    "print(\"Probabilidade de sobrevivência dado sexo\")\n",
    "sexes = train_df['Sex'].unique()\n",
    "for i,s in enumerate(sexes):\n",
    "    prob_survived_given_class = inference.query(variables=['Survived'], evidence={'Sex': i})\n",
    "    print(f\"Sexo {s}:\")\n",
    "    print(prob_survived_given_class)\n",
    "\n",
    "print(\"Probabilidade do passageiro ter uma família grande dado que ele sobreviveu\")\n",
    "prob_family_size_given_survived = inference.query(variables=['Family_Size'], evidence={'Survived': 1})\n",
    "print(prob_family_size_given_survived)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
